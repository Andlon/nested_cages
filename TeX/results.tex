\section{Results and applications}
\label{sec:results}

\begin{figure}
  \includegraphics[width=0.32\linewidth]{figs/decim_holder_0}
    \includegraphics[width=0.32\linewidth]{figs/decim_holder_1}
      \includegraphics[width=0.32\linewidth]{figs/decim_holder_2}
  \caption{Our cages inherit regularity from the prescribed initial decimations.
  The choice for initial decimation affects the final quality of our result,
  and the user can opt for more adaptive or regular meshes.}
  \label{fig:decimations}
\end{figure}

We have implemented our method as a serial Matlab program
that calls functions for initial decimation, flow and re-inflation.
The default for the initial (overlapping) decimations
were the ones provided by the \cite{cgal} library, but the user may
switch to the more adaptive meshes provided by the OpenMesh
Library \cite{openmesh}.This choice affects the final result as
we show in Figure~\ref{fig:decimations}.  In case these initial coarse
meshes self-intersect,
we remove their intersections with Meshfix \cite{Attene:2010vv}. The interface to the
physical simulation libraries were done as MEX-files.

\begin{figure}
  \includegraphics[width=\linewidth]{figs/energies_volume_surfarap.png}
  \caption{The cage obtained by minimizing the volume energy (left)
  does present a tight fit but may lead to mesh quality artefacts.
  On the other hand, minimizing surface ARAP (right) preserves the mesh
  quality of the initial (non-regular) decimation but leads to extra volume.}
  \label{fig:energies}
\end{figure}

Figure~\ref{fig:energies} shows the different results that our method obtains
for different choices of energies. Volume minimization leads to a very
tight-fitting cage, but may harm mesh quality and lead to \leo{Vacuum effect,
please help me write this}. Switching to surface ARAP removes the mesh quality
artefacts by restoring the original intrinsics of the give initial coarse mesh,
but may present extra volume.

\begin{figure}
  \includegraphics[width=\linewidth]{figs/hand-hc}
  \caption{Left to right: a quad mesh is quickly sketched atop the \emph{Hand}
  and our pipeline moves it outside the input while planarizing quads. A
  cage-based deformation is applied via harmonic coordinates computed over the
  volume inside the planar-quad polyhedron (a few coordinates visualized in
  pseudocolor). These weights are smooth inside each quad. In contrast,
  triangulating the quads would lead to non-smooth, meshing-dependent values in
  each quad (two alternative triangulations).}
  \label{fig:hand-hc}
\end{figure}

The possibility of specifying different energies in our method
gives it great flexibility to handle a variety of applications.
Despite harmonic coordinates being theoretically defined for arbitrary
polyhedra, previous works implement them only on triangle mesh cages
\cite{HarmonicCoodinates07}.
%
To utilize popular quad-dominant meshes as cages, all faces must be outside the
input model and \emph{planar}.
%
Such cages are difficult to model manually, hence opting to simply triangulate
any high-order facets \cite{HarmonicCoodinates07}.
%
We complement the recent sketch-based quad meshing tool \cite{Takayama:2013},
post-processing its output to enclose the input model and
minimize a planarization energy \cite{poranne2013interactive}.
%
Quad-dominant cages are easier to control as their visualization is less
cluttered (see \reffig{hand-hc}).
%
More importantly, harmonic coordinates constructed (via their recursive
definition) on the planar-quad polyhedron are also higher quality:
coordinates are smooth functions inside each quad.
%
In contrast, coordinates would depend heavily on the chosen triangulation.

\begin{figure}
  \includegraphics[width=\linewidth]{figs/swat-cage}
  \caption{The \emph{S.W.A.T. man} is an artifact-ridden mesh with 2806 pairs
  of intersecting triangles, 24 non-manifold edges, 51 boundary loops and 51
  connected components. Our shrinking flow to the input overlapping coarse cage
  is robust to such artifacts. Once inside, we re-inflate and produce a fully
  exterior cage used to deform the embedded model.}
  \label{fig:swat-cage}
\end{figure}

In animation it is often desired to have a cage that respects semantic
properties of the object, such as symmetry. In the case where a symmetric overlapping
decimation was designed by an artist (Figure~\ref{fig:swat-cage}, left), we can use our method
to obtain a fully exterior that preserves symmetry, by minimizing a symmetry energy.
There is no need for the input fine mesh to be symmetric, as demonstrated
by our result in Figure~\ref{fig:swat-cage}. We also point that our method works
even if the input mesh has a lot of problems, since it is agnostic to input mesh quality.


\begin{figure}
  \includegraphics[width=\linewidth]{figs/frankenstein-physics}
  \caption{Extracting an outer hull with \protect\cite{Jacobson:WN:2013} fails
  to coarsen the domain away from the original discretization (top left). Contouring
  the signed distance field \protect\cite{Xu:2014:SDF} achieves true nesting at
  a large iso-level fusing the legs (top center). Our method fits the input
  tightly (top right). The coarse mesh provides a low-dimensional domain for
  real-time physical simulation (middle) and simple interpolation onto the
  input mesh (bottom).}
  \label{fig:frankenstein-physics}
\end{figure}

In Figure~\ref{fig:frankenstein-physics} we show
how our cages find applications in real-time physical simulation where
fast simulation can be performed on the coarse cage and faithfully
interpolated to the high-resolution model, due to tight-fitness.
An alternative would be obtain a cage by extracting
the outer hull with \cite{Jacobson:WN:2013}, but this fails to obtain
coarseness since many sliver triangles appear near self-intersections (inset).
\cite{Xu:2014:SDF} produces a coarse cage at the expense
of losing tight-fitness.

\begin{figure}
  \includegraphics[width=\linewidth]{figs/noisy-bunny}
  \caption{Noise add in the normal direction to the input bunny does not
  affect our ability to generate seven quality outer layers.}
  \label{fig:noisy-bunny}
\end{figure}

Our method can also handle noisey input as shown in Figure~\ref{fig:noisy-bunny}.
We added noise in the normal direction for the top model and 
re-ran our pipeline with the exact same settings, leading to the cages on the bottom.
It can be seen that noise is smoothed out across layers. 

To showcase the quality and robustness of our method we present more results 
in Figure~\ref{fig:zoo}. We have generated each coarser layer with $2^{-\frac{2}{3}}$
the number of faces of the previous layer. This way a tet-mesh generated inside
the coarser layer with default settings (\leo{I think ot needs more details}) has
approximately half the number of tets of a tet-mesh defined inside the previous
fine layer. We targeted to generate 7 cages for each result, except for the Maxplank
that we generated 50 layers to stress robustness of our method, and some meshes that
were already low resolution and initial decimations started losing features with
the resolution convention we have adopted.

Table~\ref{tab:timings} present timing data for some of the results.  Volumetric ARAP
and volume energy are considrably faster then surface ARAP, since the latter has more
space for minimization and takes more gradient projection steps to converge.
The table also evidences that the most time-consuming
part of our pipeline is the physical simulation, as expected.

\input{timings_table}

\begin{figure}
  \includegraphics[width=\linewidth]{figs/octopus-poisson}
  \caption{A single multiresolution v-cycle takes 1.4 secs on this 7M-vertex
  volumetric Poisson equation in the \emph{Octopus}. With 14 more iterations
  (21 secs) the residual error matches a direct solver's (11 mins, back
  substitution only).}
  \label{fig:octopus-poisson}
\end{figure}


%
Constructing our nested cages can be considered expensive \emph{precomputation}
for a multiresolution linear system solver.
%
However, once meshes are computed the multigrid solver is sleek and memory
efficient.
%
A single multiresolution V-cycle for a Poisson equation with Dirichlet boundary
conditions inside the volume of the \emph{Octopus} with over seven million
vertices, takes 1.4 seconds using 2GB max memory. With 14 more V-cycles the
solution converges for a total time of 21 seconds (see
\reffig{octopus-poisson}).
%
In contrast, \textsc{Matlab}'s backslash operator thrashes when using over 22GB
of memory finishing in over 16 minutes.
%
\textsc{Cholmod}'s Cholesky factorization with reordering is mildly better than
\textsc{Matlab}, solving via backsubstitution in 10 minutes, but suffers from
similar memory issues during the pre-factorization procedures, which takes over
an hour to complete using 17GB max memory.
%
In terms of precomputation, our time consuming cage computation lives at a much
earlier stage than pre-factorization: before determining constraints or
boundary conditions and before even choosing the particular system being
solved.

\begin{wrapfigure}{r}{1.02in}
%
\centering
%
\includegraphics[width=\linewidth]{figs/pelvis-plot}
%
\end{wrapfigure}
%
As we do not alter the core iterative nature of multiresolution, we benefit
from its flexibility. For example, we may quickly change the diffusion rate in
a heat equation solved in the volume of the \emph{Pelvis} (see
\reffig{pelvis-diffusion}). 
%
Factorization based solvers, in general scrap previous precomputation after
such a global change to the system matrix. 
%
Multiresolution hardly notices and may even use previous solutions as a warm
start if changes to the system are slight.
%
In this example, we employ Neumann boundary conditions and notice that naively
decimating the input mesh leads to a divergent solver (inset).

\begin{figure}
  \includegraphics[width=\linewidth]{figs/armadillo-heat-plot}
  \caption{We solve for smooth geodesics via two Poisson equations over a
  tetrahedal mesh of the \emph{Armadillo}. Multiresolution using naive
  overlapping and shrinking decimations leads to divergence unless a very large
  number of relaxation iterations is used in each level in each v-cycle. Ours
  is always convergent.}
  \label{fig:armadillo-heat-plot}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{figs/pelvis-diffusion}
  \caption{We solve a diffusion equation $(λ∆+I) x = b$ for various diffusion
  rates $λ$ with our nested cages in a multiresolution solver (top: surface
  values via Neumann boundary conditions, bottom: slice through tet-mesh
  volume).}
  \label{fig:pelvis-diffusion}
\end{figure}

\leo{To-do: Efficient collision detection and response (Etienne)}

\paragraph{Limitations}
%

- local pairwise subproblems make solution tractable, but could get stuck in an
  artificial local minimum: ref homer figure. If medium layer collides with
  self, may pinch blocking subsequent coarse layers. One idea is to cycle
  through layer optimizations again to make room.

The standard parameters we have set in our method have problems in some specific
cases. When the initial coarse mesh has thin features, evolving the fine mesh
with the default step size may take it outside the coarse mesh, stepping it back
and forth through the coarse mesh's medial axis. In this case,
a smaller time step can be used and the whole pipeline will take longer.
The other alternative is to expand the coarse mesh towards the gradient
of its own signed distance field and this is effective when a few expansion steps
are needed. When the expanded coarse mesh gets far away from the fine mesh,
poor energy local minima can be obtained in the re-inflation step.

- improve performance of multiresolution solver, consider preconditioners for
  conjugate gradient and more elaborate boundary conditions where our nesting
  should have an even greater beneficial effect.

\begin{figure*}
  \includegraphics[width=\linewidth]{figs/zoo}
  \caption{Each row shows left to right: input model, slice through all nested
  layers, and outermost, coarsest layer.}
  \label{fig:zoo}
\end{figure*}
